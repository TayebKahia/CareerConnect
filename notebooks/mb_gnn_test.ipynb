{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45608272",
   "metadata": {},
   "source": [
    "# 1. Convert NetworkX Graph to PyTorch Geometric Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ed7c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Map node names to indices\n",
    "node_names = list(G.nodes)\n",
    "node_to_idx = {name: idx for idx, name in enumerate(node_names)}\n",
    "\n",
    "# Create node features (average of main and abbr embeddings if available)\n",
    "node_features = []\n",
    "for node_name in node_names:\n",
    "    concept = next(c for c in processed_concepts if c['name'] == node_name)\n",
    "    idx = processed_concepts.index(concept)\n",
    "    main_emb_i = main_emb[idx]\n",
    "    abbr_emb_i = abbr_emb[idx] if concept['abbr'] else None\n",
    "    feature = (main_emb_i + abbr_emb_i) / 2 if abbr_emb_i is not None else main_emb_i\n",
    "    node_features.append(feature)\n",
    "\n",
    "node_features = torch.tensor(np.array(node_features), dtype=torch.float)\n",
    "\n",
    "# Create edge indices\n",
    "edge_list = []\n",
    "for u, v in G.edges():\n",
    "    edge_list.append([node_to_idx[u], node_to_idx[v]])\n",
    "    edge_list.append([node_to_idx[v], node_to_idx[u]])  # Undirected\n",
    "\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create PyG Data object\n",
    "graph_data = Data(x=node_features, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa787d0",
   "metadata": {},
   "source": [
    "# 2. Define GNN Model with Contrastive Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1e697",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def contrastive_loss(z, edge_index, neg_samples=5):\n",
    "    src, dst = edge_index\n",
    "    pos_pairs = torch.stack([src, dst], dim=1)\n",
    "    \n",
    "    # Negative sampling\n",
    "    neg_src = torch.randint(0, z.size(0), (src.size(0)*neg_samples,))\n",
    "    neg_dst = torch.randint(0, z.size(0), (src.size(0)*neg_samples,))\n",
    "    neg_pairs = torch.stack([neg_src, neg_dst], dim=1)\n",
    "    \n",
    "    # Similarity calculation\n",
    "    pos_sim = F.cosine_similarity(z[pos_pairs[:,0]], z[pos_pairs[:,1]])\n",
    "    neg_sim = F.cosine_similarity(z[neg_pairs[:,0]], z[neg_pairs[:,1]])\n",
    "    \n",
    "    # Loss\n",
    "    loss = -torch.log(torch.sigmoid(pos_sim)).mean() + torch.log(torch.sigmoid(-neg_sim)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d833c6",
   "metadata": {},
   "source": [
    "# 3. Train the GNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9c87b",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GNN(input_dim=768, hidden_dim=256, output_dim=768).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "graph_data = graph_data.to(device)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    z = model(graph_data)\n",
    "    loss = contrastive_loss(z, graph_data.edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbefb90",
   "metadata": {},
   "source": [
    "# 4. Generate Enhanced Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb31bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    enhanced_embeddings = model(graph_data).cpu().numpy()\n",
    "\n",
    "# Map back to original concepts\n",
    "concept_to_enhanced = {name: enhanced_embeddings[node_to_idx[name]] for name in node_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20bc41f",
   "metadata": {},
   "source": [
    "# 5. Recompute Job Embeddings with Enhanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_job_embeddings = []\n",
    "for job in jobs:\n",
    "    job_vec = np.zeros_like(enhanced_embeddings[0])\n",
    "    total_terms = 0\n",
    "\n",
    "    for tech_skill in job.get(\"technology_skills\", []):\n",
    "        terms = [tech_skill.get(\"skill_title\", \"\")] + [t[\"name\"]\n",
    "                                                       for t in tech_skill.get(\"technologies\", [])]\n",
    "\n",
    "        for term in terms:\n",
    "            if term in concept_to_enhanced:\n",
    "                job_vec += concept_to_enhanced[term]\n",
    "                total_terms += 1\n",
    "\n",
    "    if total_terms > 0:\n",
    "        job_vec /= total_terms\n",
    "    enhanced_job_embeddings.append(job_vec)\n",
    "\n",
    "enhanced_job_embeddings = np.array(enhanced_job_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839d482",
   "metadata": {},
   "source": [
    "# 6. Modify Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs_with_gnn(filtered_candidates, top_n=5):\n",
    "    # Create user embedding using enhanced concept embeddings\n",
    "    user_vec = np.zeros_like(enhanced_job_embeddings[0])\n",
    "    total_weight = 0.0\n",
    "\n",
    "    for candidate in filtered_candidates:\n",
    "        name, c_type, _, score = candidate\n",
    "        if name not in concept_to_enhanced:\n",
    "            continue\n",
    "\n",
    "        weight = score * (1.0 if c_type == \"technology_name\" else 0.7)\n",
    "        user_vec += concept_to_enhanced[name] * weight\n",
    "        total_weight += weight\n",
    "\n",
    "    if total_weight > 0:\n",
    "        user_vec /= total_weight\n",
    "\n",
    "    # Calculate similarities with enhanced job embeddings\n",
    "    sims = cosine_similarity([user_vec], enhanced_job_embeddings)[0]\n",
    "    top_indices = np.argsort(sims)[-top_n:][::-1]\n",
    "\n",
    "    return [(job_titles[i], sims[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a134d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with sample skills\n",
    "sample_skills = [\n",
    "    (\"Python (Python)\", \"technology_name\", 0.95),\n",
    "    (\"Machine Learning\", \"skill_title\", 0.88)\n",
    "]\n",
    "\n",
    "recommended = recommend_jobs_with_gnn(sample_skills)\n",
    "for job, score in recommended:\n",
    "    print(f\"{job}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3071ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
